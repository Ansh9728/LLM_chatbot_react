# Frontend and Backend Application Setup

`main.py` which is the entry point to our server
2. This project has a few Python packages as dependencies, you can install them in your virtual environment using `requirements.txt`. 

Then install the python packages using `pip install -r requirements.txt`
#### Running the backend server

To launch the server, navigate to the `backend` directory and run:

##### `uvicorn main:app --reload`

This will start the server at [http://127.0.0.1:8000/](http://127.0.0.1:8000/)

#### How to launch the react app

1. Navigate to the `frontend` directory and run `npm install`
2. Then you can run:

   ##### `npm start`

   This will launch the app in development mode.\
   Open [http://localhost:3000](http://localhost:3000) to view it in the browser.

The page will reload if you make edits. You will also see any lint errors in the console.


## Frontend Application Documentation

The frontend application is designed to interact with a backend server to perform tasks such as submitting questions and uploading files.

## Setup

### Prerequisites
- Node.js installed on your machine

### Installation
1. Navigate to the `frontend` directory:


This will launch the app in development mode. Open [http://localhost:3000](http://localhost:3000) to view it in the browser. The page will reload if you make edits. You will also see any lint errors in the console.

## Usage

- Upon launching the frontend application, you will be presented with a form where you can enter a question and upload a file.
- After filling out the form, click the "Submit" button to send the data to the backend server.
- If successful, the result will be displayed below the form.

## Backend Application Documentation

The backend application serves as the server-side component of the application, responsible for processing files and questions submitted by the frontend application. This documentation outlines the approach and functionality of the backend application.

## Setup

### Prerequisites
- Python installed on your machine
- FastAPI and Uvicorn installed (you can install them via pip)
- Hugging Face access token stored in a `.env` file

### Installation
1. Navigate to the `backend` directory:


## Functionality

### File Processing
- Upon receiving a file from the frontend application, the backend application first reads the contents of the file.
- The file content is then cleaned using the `clean_file_content` function from the `util_func` module. This function performs any necessary preprocessing steps to prepare the file content for further processing.

### Summarization
- The cleaned file content is passed to the Hugging Face summarization API (`https://api-inference.huggingface.co/models/Falconsai/text_summarization`) to generate a summary of the document.
- The summarization API request is constructed using a JSON object with the file content as input, along with additional parameters for the summarization model.
- The resulting summary text is extracted from the API response.

### Question Answering
- The generated summary text and the user's question are passed to a custom language model (LLM) using the `process_with_llm` function from the `util_func` module.
- The `process_with_llm` function processes the summary text and question to generate an answer using the language model.
- The generated answer is returned as the result.

## API Endpoint

### `/predict` Endpoint
- **Method:** POST
- **Parameters:**
- `file`: UploadFile (required) - The file submitted by the user.
- `question`: str (required) - The question submitted by the user.
- **Response:**
- `result`: str | None - The answer generated by the backend application.

## Usage
- To use the backend application, ensure that the prerequisites are met and the environment variables (such as the Hugging Face access token) are properly configured.
- Start the server using the command `uvicorn main:app --reload`.
- The frontend application can then submit file and question data to the `/predict` endpoint for processing.


